This is the folder for HW10. I got an extension for this homework.

I spent quite a while understanding neural networks (and I'm still wrapping my head around it), and getting to familiarize myself with the processes. This homework shows an implementation of Neural Networks, the process of modifying/improving our NN model to gain more "accurate" predictions. Through this homework, I found that one of the most important way to assess how the model is doing, besides explicitly comparing it to the "real" data, is by looking at the loss function. When plotting the loss vs. the "epoch" (which in some way determines how we "fit" the neural network progress), we want the loss to (generally) be decreasing. The way I understand this is that we want to minimize our loss (optimize the model), so we see how the model is "learning" this way. 

In this HW particularly, we eventually implemented Physics-informed NN (PiNN), which is the neural network run with loss function and conditions based on physical knowledge/equations. Here, we were striving to predict values of velocity as a function of time and position, with respect to the Burger's equation. Even after implementing PiNN, we were still changing the epoch (increasing it) and the learning rate to better our model. 

Throughout this homework, I mostly followed the code from class by Prof. Bianco, but I had to spend more time understanding the gist of what each part of the code does. I looked at documentations and other examples of running a neural network to gain more insight; some helped but some also led me to even more questions. Though, Paula helped me a lot in understanding the structure of the code and why we need to plot certain things, and how each step should connect to the other. 

The somewhat daunting part about this homework is running the neural network. I ran out of GPU in the middle of running this homework, so I ended up having to wait, sit, and watch for a long time to run the rest of it. This can be very time consuming, especially when I know I have other things to do at the moment. And this brought me quite some anxiety, thinking about the possibility that my notebook could be disconnected and would have to run all over again. So I consulted with Prof. Bianco, and she suggested that I could save the NN weights at intermediate training epochs. Therefore, I will need to train myself how to do this before the final, and in general, as this would be a very helpful skill given limited GPU resources.
